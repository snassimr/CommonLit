{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snassimr/CommonLit/blob/master/CommonLit_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY5ilTHy_WxF"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tv7US0CF_HyE"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ing0udi_eZe",
        "outputId": "b5ef1656-1889-4c4b-b986-f46961988eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A7Xaez3cAtHH"
      },
      "outputs": [],
      "source": [
        "SYS_PROJECT_DIR = '/content/gdrive/MyDrive/Colab Notebooks/CommonLit/V2'\n",
        "SYS_INPUT_DIR   = '/content/gdrive/MyDrive/Colab Notebooks/CommonLit'\n",
        "SYS_OUTPUT_DIR   = '/content/gdrive/MyDrive/Colab Notebooks/CommonLit/V2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SvDFm5dAAih0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sngMaG2Z9OGi"
      },
      "outputs": [],
      "source": [
        "# shutil.rmtree('test123')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FY6H4Lg_vGa"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zhu4cJN_484"
      },
      "source": [
        "## Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vJlGqtPx_vlx"
      },
      "outputs": [],
      "source": [
        "prompts_train   = pd.read_csv(os.path.join(SYS_INPUT_DIR,'prompts_train.csv'))\n",
        "summaries_train = pd.read_csv(os.path.join(SYS_INPUT_DIR,'summaries_train.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "VCXKYfGuAULD",
        "outputId": "78827847-76e6-4022-d653-866e57ae7ab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompts train shape: (4, 4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  prompt_id                                    prompt_question  \\\n",
              "0    39c16e  Summarize at least 3 elements of an ideal trag...   \n",
              "1    3b9047  In complete sentences, summarize the structure...   \n",
              "2    814d6b  Summarize how the Third Wave developed over su...   \n",
              "3    ebad26  Summarize the various ways the factory would u...   \n",
              "\n",
              "                prompt_title  \\\n",
              "0                 On Tragedy   \n",
              "1  Egyptian Social Structure   \n",
              "2             The Third Wave   \n",
              "3    Excerpt from The Jungle   \n",
              "\n",
              "                                         prompt_text  \n",
              "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  \n",
              "1  Egyptian society was structured like a pyramid...  \n",
              "2  Background \\r\\nThe Third Wave experiment took ...  \n",
              "3  With one member trimming beef in a cannery, an...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e907e27-aa4b-4ae0-940c-c11568ae5fd5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39c16e</td>\n",
              "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
              "      <td>On Tragedy</td>\n",
              "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3b9047</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>814d6b</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ebad26</td>\n",
              "      <td>Summarize the various ways the factory would u...</td>\n",
              "      <td>Excerpt from The Jungle</td>\n",
              "      <td>With one member trimming beef in a cannery, an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e907e27-aa4b-4ae0-940c-c11568ae5fd5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e907e27-aa4b-4ae0-940c-c11568ae5fd5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e907e27-aa4b-4ae0-940c-c11568ae5fd5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary train shape: (7165, 5)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     student_id prompt_id                                               text  \\\n",
              "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
              "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
              "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
              "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
              "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
              "\n",
              "    content   wording  \n",
              "0  0.205683  0.380538  \n",
              "1 -0.548304  0.506755  \n",
              "2  3.128928  4.231226  \n",
              "3 -0.210614 -0.471415  \n",
              "4  3.272894  3.219757  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ae44f66-f321-40cd-a738-3f4d5f32f923\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000e8c3c7ddb</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave was an experimentto see how peo...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0020ae56ffbf</td>\n",
              "      <td>ebad26</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>-0.548304</td>\n",
              "      <td>0.506755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>004e978e639e</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>3.128928</td>\n",
              "      <td>4.231226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>005ab0199905</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>-0.210614</td>\n",
              "      <td>-0.471415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0070c9e7af47</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>3.272894</td>\n",
              "      <td>3.219757</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ae44f66-f321-40cd-a738-3f4d5f32f923')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ae44f66-f321-40cd-a738-3f4d5f32f923 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ae44f66-f321-40cd-a738-3f4d5f32f923');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ff81e29d-19fc-4714-a663-f3626fb9fffd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff81e29d-19fc-4714-a663-f3626fb9fffd')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ff81e29d-19fc-4714-a663-f3626fb9fffd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(f\"Prompts train shape: {prompts_train.shape}\")\n",
        "display(prompts_train.head())\n",
        "print(f\"Summary train shape: {summaries_train.shape}\")\n",
        "display(summaries_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "pUNiAgtQlzQR",
        "outputId": "bac240b0-87f5-4012-ec71-0f05eaf779af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     student_id prompt_id                                               text  \\\n",
              "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
              "1  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
              "2  0095993991fe    814d6b  The third wave only started as an experiment w...   \n",
              "3  00c20c6ddd23    814d6b  The experimen was orginally about how even whe...   \n",
              "4  00d40ad10dc9    814d6b  The third wave developed so quickly due to the...   \n",
              "\n",
              "    content   wording                                    prompt_question  \\\n",
              "0  0.205683  0.380538  Summarize how the Third Wave developed over su...   \n",
              "1  3.272894  3.219757  Summarize how the Third Wave developed over su...   \n",
              "2  0.205683  0.380538  Summarize how the Third Wave developed over su...   \n",
              "3  0.567975  0.969062  Summarize how the Third Wave developed over su...   \n",
              "4 -0.910596 -0.081769  Summarize how the Third Wave developed over su...   \n",
              "\n",
              "     prompt_title                                        prompt_text  \n",
              "0  The Third Wave  Background \\r\\nThe Third Wave experiment took ...  \n",
              "1  The Third Wave  Background \\r\\nThe Third Wave experiment took ...  \n",
              "2  The Third Wave  Background \\r\\nThe Third Wave experiment took ...  \n",
              "3  The Third Wave  Background \\r\\nThe Third Wave experiment took ...  \n",
              "4  The Third Wave  Background \\r\\nThe Third Wave experiment took ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-503a12d5-71d6-4657-9904-a09fdfe0d340\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000e8c3c7ddb</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave was an experimentto see how peo...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0070c9e7af47</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>3.272894</td>\n",
              "      <td>3.219757</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0095993991fe</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave only started as an experiment w...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00c20c6ddd23</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The experimen was orginally about how even whe...</td>\n",
              "      <td>0.567975</td>\n",
              "      <td>0.969062</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00d40ad10dc9</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave developed so quickly due to the...</td>\n",
              "      <td>-0.910596</td>\n",
              "      <td>-0.081769</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-503a12d5-71d6-4657-9904-a09fdfe0d340')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-503a12d5-71d6-4657-9904-a09fdfe0d340 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-503a12d5-71d6-4657-9904-a09fdfe0d340');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c21df3d1-adb9-41f4-b7f3-45db19c8248e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c21df3d1-adb9-41f4-b7f3-45db19c8248e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c21df3d1-adb9-41f4-b7f3-45db19c8248e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Perform the inner join based on the 'prompt_id' column\n",
        "train = pd.merge(summaries_train, prompts_train,\n",
        "              on='prompt_id', how='inner')\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XmSe7LGql9EU"
      },
      "outputs": [],
      "source": [
        "#############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOESRxXlAMus"
      },
      "source": [
        "## Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d-JaWeW0ANKw"
      },
      "outputs": [],
      "source": [
        "prompts_test   = pd.read_csv(os.path.join(SYS_INPUT_DIR,'prompts_test.csv'))\n",
        "summaries_test = pd.read_csv(os.path.join(SYS_INPUT_DIR,'summaries_test.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "HC3EQ1rdAf_E",
        "outputId": "8656cab9-1ece-4d19-de8e-38bbe4659fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompts test shape: (2, 4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  prompt_id prompt_question     prompt_title       prompt_text\n",
              "0    abc123    Summarize...  Example Title 1  Heading\\nText...\n",
              "1    def789    Summarize...  Example Title 2  Heading\\nText..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-085911c7-ce79-4a97-89c9-a2b08dd8045a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abc123</td>\n",
              "      <td>Summarize...</td>\n",
              "      <td>Example Title 1</td>\n",
              "      <td>Heading\\nText...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>def789</td>\n",
              "      <td>Summarize...</td>\n",
              "      <td>Example Title 2</td>\n",
              "      <td>Heading\\nText...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-085911c7-ce79-4a97-89c9-a2b08dd8045a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-085911c7-ce79-4a97-89c9-a2b08dd8045a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-085911c7-ce79-4a97-89c9-a2b08dd8045a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary test shape: (4, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     student_id prompt_id            text\n",
              "0  000000ffffff    abc123  Example text 1\n",
              "1  111111eeeeee    def789  Example text 2\n",
              "2  222222cccccc    abc123  Example text 3\n",
              "3  333333dddddd    def789  Example text 4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39d512b4-9fbf-4b5f-9b51-cafae3bc675b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000000ffffff</td>\n",
              "      <td>abc123</td>\n",
              "      <td>Example text 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>111111eeeeee</td>\n",
              "      <td>def789</td>\n",
              "      <td>Example text 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>222222cccccc</td>\n",
              "      <td>abc123</td>\n",
              "      <td>Example text 3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>333333dddddd</td>\n",
              "      <td>def789</td>\n",
              "      <td>Example text 4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39d512b4-9fbf-4b5f-9b51-cafae3bc675b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39d512b4-9fbf-4b5f-9b51-cafae3bc675b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39d512b4-9fbf-4b5f-9b51-cafae3bc675b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(f\"Prompts test shape: {prompts_test.shape}\")\n",
        "display(prompts_test.head())\n",
        "print(f\"Summary test shape: {summaries_test.shape}\")\n",
        "display(summaries_test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "0PqzUJ8FDQtE",
        "outputId": "ec79e1e8-7cdc-4c5d-930a-957aabbd1a90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     student_id prompt_id            text prompt_question     prompt_title  \\\n",
              "0  000000ffffff    abc123  Example text 1    Summarize...  Example Title 1   \n",
              "1  222222cccccc    abc123  Example text 3    Summarize...  Example Title 1   \n",
              "2  111111eeeeee    def789  Example text 2    Summarize...  Example Title 2   \n",
              "3  333333dddddd    def789  Example text 4    Summarize...  Example Title 2   \n",
              "\n",
              "        prompt_text  \n",
              "0  Heading\\nText...  \n",
              "1  Heading\\nText...  \n",
              "2  Heading\\nText...  \n",
              "3  Heading\\nText...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4dd312d4-7944-41ac-a5cb-9d787c558477\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000000ffffff</td>\n",
              "      <td>abc123</td>\n",
              "      <td>Example text 1</td>\n",
              "      <td>Summarize...</td>\n",
              "      <td>Example Title 1</td>\n",
              "      <td>Heading\\nText...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>222222cccccc</td>\n",
              "      <td>abc123</td>\n",
              "      <td>Example text 3</td>\n",
              "      <td>Summarize...</td>\n",
              "      <td>Example Title 1</td>\n",
              "      <td>Heading\\nText...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>111111eeeeee</td>\n",
              "      <td>def789</td>\n",
              "      <td>Example text 2</td>\n",
              "      <td>Summarize...</td>\n",
              "      <td>Example Title 2</td>\n",
              "      <td>Heading\\nText...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>333333dddddd</td>\n",
              "      <td>def789</td>\n",
              "      <td>Example text 4</td>\n",
              "      <td>Summarize...</td>\n",
              "      <td>Example Title 2</td>\n",
              "      <td>Heading\\nText...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4dd312d4-7944-41ac-a5cb-9d787c558477')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4dd312d4-7944-41ac-a5cb-9d787c558477 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4dd312d4-7944-41ac-a5cb-9d787c558477');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Perform the inner join based on the 'prompt_id' column\n",
        "test = pd.merge(summaries_test, prompts_test,\n",
        "              on='prompt_id', how='inner')\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJrMmPXrCTLV"
      },
      "source": [
        "## Prompt for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nJSmWYkVCTxo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "prompt_ft_instruction = f\"\"\"\n",
        "### Instruction:\n",
        "Learn relationship between prompt_text , prompt_question and text to score.\n",
        "Score expresses how well answer_text matches prompt_text based on prompt_text.\n",
        "\"\"\"\n",
        "def create_train_prompt_ft(df : pd.DataFrame, target : str):\n",
        "\n",
        "    from tqdm import trange\n",
        "\n",
        "    prompts = list()\n",
        "    for i in trange(len(df.index)):\n",
        "\n",
        "        prompt_ft = prompt_ft_instruction + \\\n",
        "        f\"\"\"\n",
        "        ### Input:\n",
        "        prompt_text:\n",
        "        {df.iloc[i].prompt_text}\n",
        "        prompt_question:\n",
        "        {df.iloc[i].prompt_question}\n",
        "        answer_text:\n",
        "        {df.iloc[i].text}\n",
        "\n",
        "        ### Response:\n",
        "        score:\n",
        "        {df.iloc[i].content}\n",
        "        \"\"\"\n",
        "\n",
        "        prompts.append(prompt_ft)\n",
        "\n",
        "    return prompts\n",
        "\n",
        "def create_test_prompt_ft(df : pd.DataFrame, target : str):\n",
        "\n",
        "    from tqdm import trange\n",
        "\n",
        "    prompts = list()\n",
        "    for i in trange(len(df.index)):\n",
        "\n",
        "        prompt_ft = prompt_ft_instruction + \\\n",
        "        f\"\"\"\n",
        "        ### Input:\n",
        "        prompt_text:\n",
        "        {df.iloc[i].prompt_text}\n",
        "        prompt_question:\n",
        "        {df.iloc[i].prompt_question}\n",
        "        answer_text:\n",
        "        {df.iloc[i].text}\n",
        "\n",
        "        ### Response:\n",
        "        Output score here\n",
        "        \"\"\"\n",
        "\n",
        "        prompts.append(prompt_ft)\n",
        "\n",
        "    return prompts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRzGdj2ND1hC",
        "outputId": "f4b34fea-0462-4f50-c023-cfea0e017ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 7165/7165 [00:02<00:00, 3038.03it/s]\n",
            "100%|| 7165/7165 [00:02<00:00, 3073.14it/s]\n"
          ]
        }
      ],
      "source": [
        "for target in [\"content\", \"wording\"]:\n",
        "    prompts = create_train_prompt_ft(\n",
        "        train,\n",
        "        target=target\n",
        "    )\n",
        "    train['prompt_train_ft_' + target] = prompts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for target in [\"content\", \"wording\"]:\n",
        "    prompts = create_test_prompt_ft(\n",
        "        train,\n",
        "        target=target\n",
        "    )\n",
        "    train['prompt_test_ft_' + target] = prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBIjIh8bxpMn",
        "outputId": "431b50bd-d449-4c84-b7cb-e1ec538c9340"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 7165/7165 [00:01<00:00, 4296.28it/s]\n",
            "100%|| 7165/7165 [00:01<00:00, 4210.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for target in [\"content\", \"wording\"]:\n",
        "    prompts = create_test_prompt_ft(\n",
        "        test,\n",
        "        target=target\n",
        "    )\n",
        "    test['prompt_ft_' + target] = prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_3GH9H_f0Ll",
        "outputId": "33dba7a7-62f6-4d1f-b156-62b015a6396b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 4/4 [00:00<00:00, 5174.96it/s]\n",
            "100%|| 4/4 [00:00<00:00, 4320.68it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY5kNHehDCRe"
      },
      "source": [
        "# Set Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tqTNR83oDCrk"
      },
      "outputs": [],
      "source": [
        "# set random seed\n",
        "def seed_everything(seed: int):\n",
        "    import random, os\n",
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "seed_everything(seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbKt6WQSWM2Z"
      },
      "source": [
        "# Model Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw9VhIZ7upZj"
      },
      "source": [
        "## Prepare LLaMA model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeHUyJuGz44Z",
        "outputId": "e7c10a52-a28d-48db-941a-c9d7ce7c741d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.4 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.22.0\n",
            "Collecting peft\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.0.1+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.32.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from peft) (0.22.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft) (16.0.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.16.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers->peft) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: peft\n",
            "Successfully installed peft-0.5.0\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.41.1\n",
            "Collecting trl\n",
            "  Downloading trl-0.6.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.0.1+cu118)\n",
            "Requirement already satisfied: transformers>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.32.0)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.23.5)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.22.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (2.14.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->trl) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->trl) (16.0.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (0.16.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.8.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2023.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->trl) (1.16.0)\n",
            "Installing collected packages: trl\n",
            "Successfully installed trl-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate -U\n",
        "!pip install peft\n",
        "!pip install bitsandbytes\n",
        "!pip install trl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
        "from datasets import Dataset\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model"
      ],
      "metadata": {
        "id": "_Recb4hE9PbN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIULUBYYr9wZ"
      },
      "source": [
        "## Initialize Model_Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "L309stGuDGw8"
      },
      "outputs": [],
      "source": [
        "Model_Config = {\n",
        "    'model_name' : 'meta-llama_Llama-2-7b-chat-hf',\n",
        "    'base_model' : {\n",
        "      'root_dir'      : 'base_model',\n",
        "      'model_name'    : 'meta-llama_Llama-2-7b-chat-hf',\n",
        "    },\n",
        "    'sft' : {\n",
        "        'optim' : \"paged_adamw_32bit\",\n",
        "        'lr_scheduler_type' : \"constant\",\n",
        "        'learning_rate' :2e-4,\n",
        "        'per_device_train_batch_size' : 2,\n",
        "        'gradient_accumulation_steps' : 2,\n",
        "        'max_grad_norm' : 0.3,\n",
        "        'warmup_ratio' : 0.03,\n",
        "        'save_steps' : 10,\n",
        "        'max_steps' : 10,\n",
        "        'logging_steps' : 5,\n",
        "\n",
        "        'max_seq_length' : 1024\n",
        "    },\n",
        "    'model_root_dir': 'model',\n",
        "    'random_seed' : 42,\n",
        "    'n_splits'    : 2,\n",
        "    'num_train_epochs' : 5\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRNc4RG1stJm"
      },
      "source": [
        "## Download and save base model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg8SQsownh6O"
      },
      "source": [
        "### Download base model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !huggingface-cli login\n",
        "# !pip install huggingface_hub"
      ],
      "metadata": {
        "id": "T-sM7lGYoVN0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jTBmAMjxPKl4"
      },
      "outputs": [],
      "source": [
        "# base_model_name = \"TinyPixel/Llama-2-7B-bf16-sharded\"\n",
        "# base_model_name = \"meta-llama/Llama-2-7b-hf\"\n",
        "# base_model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# # from huggingface_hub import login\n",
        "# # login(token = \"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\")\n",
        "\n",
        "# base_model = AutoModelForCausalLM.from_pretrained(\n",
        "#     base_model_name,\n",
        "#     trust_remote_code=True,\n",
        "#     use_auth_token=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRY5vTj7oMQE"
      },
      "source": [
        "### Save base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "98yGPk4loIVe"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# base_model_root_dir = Model_Config['base_model']['root_dir']\n",
        "# base_model_local_dir = os.path.join(SYS_PROJECT_DIR, base_model_root_dir)\n",
        "\n",
        "# if os.path.exists(base_model_local_dir):\n",
        "#   shutil.rmtree(base_model_local_dir)\n",
        "\n",
        "# # Save model\n",
        "# base_model.save_pretrained(base_model_local_dir)\n",
        "\n",
        "# # Download and save tokenizer\n",
        "# base_model_tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "# base_model_tokenizer.save_pretrained(base_model_local_dir)\n",
        "\n",
        "# # Download and save config\n",
        "# base_model_config = AutoConfig.from_pretrained(base_model_name)\n",
        "# base_model_config.save_pretrained(base_model_local_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zo5GOVqtkyUu"
      },
      "outputs": [],
      "source": [
        "#####################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare base model"
      ],
      "metadata": {
        "id": "pwZvPtCl8iHI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWV9nY-RszC2"
      },
      "source": [
        "### Load base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Fvw6TLpgfF6I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1769a159f17b4c82990e257aab98d0f2",
            "2b568c56ea32446b92eb421fcced953e",
            "eba689cc3a9b451383eaab85cbb18f62",
            "a51d37c7dc3e4cd7b152f80f479f609b",
            "881912b21c4c47d6a8f4a6e1c8cb903b",
            "b0bfae6dafcf4e5f8df2cd062868c3bb",
            "2249e3c697454b9baa7e230a75c1e762",
            "e25064ad6a9c48d0b0e3964fab69a875",
            "f452275552674a9c93eec80cb561ed9f",
            "226de1624f784403ac202bff645fda01",
            "8fd1b3a43d3e4273aeea3cd57aee7632"
          ]
        },
        "outputId": "0442a3ad-f10e-47d8-8ea1-4f5da1cc39a3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1769a159f17b4c82990e257aab98d0f2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
        "\n",
        "base_model_root_dir = Model_Config['base_model']['root_dir']\n",
        "base_model_local_dir = os.path.join(SYS_PROJECT_DIR, base_model_root_dir)\n",
        "\n",
        "def load_base_model(base_model_local_dir, model_config):\n",
        "\n",
        "    n_gpus = torch.cuda.device_count()\n",
        "    max_memory = f'{12288}MB'\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        base_model_local_dir,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\", # dispatch efficiently the model on the available resources\n",
        "        max_memory = {i: max_memory for i in range(n_gpus)},\n",
        "    )\n",
        "\n",
        "    model.config.use_cache = False\n",
        "    model.config.pretraining_tp = 1\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model_local_dir)\n",
        "\n",
        "    # Needed for LLaMA tokenizer\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    config  = AutoConfig.from_pretrained(base_model_local_dir)\n",
        "\n",
        "    config.update(Model_Config['base_model'])\n",
        "\n",
        "    return model, tokenizer, config\n",
        "\n",
        "base_model, base_model_tokenizer, base_model_config = load_base_model(base_model_local_dir, Model_Config)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZMcRef7qqE3"
      },
      "source": [
        "## Update Model_Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Hd2-X74EqucY"
      },
      "outputs": [],
      "source": [
        "Model_Config['base_model']['model']      = base_model\n",
        "Model_Config['base_model']['tokenizer']  = base_model_tokenizer\n",
        "Model_Config['base_model']['config']     = base_model_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "aF1NcaGJ13rE"
      },
      "outputs": [],
      "source": [
        "################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdxupqUxvTgC"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgRyH-eNvXGO"
      },
      "source": [
        "## Create folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qOkRVD0USDzu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "\n",
        "gkf = GroupKFold(n_splits = Model_Config['n_splits'])\n",
        "\n",
        "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
        "    train.loc[val_index, \"fold\"] = i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK9cx_p_vjSG"
      },
      "source": [
        "## Define evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CzrogygNvjp_"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "\n",
        "    predictions, labels = eval_pred\n",
        "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
        "    return {\"rmse\": rmse}\n",
        "\n",
        "def compute_mcrmse(eval_pred):\n",
        "    \"\"\"\n",
        "    Calculates mean columnwise root mean squared error\n",
        "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
        "    \"\"\"\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
        "    mcrmse = np.mean(col_rmse)\n",
        "\n",
        "    return {\n",
        "        \"content_rmse\": col_rmse[0],\n",
        "        \"wording_rmse\": col_rmse[1],\n",
        "        \"mcrmse\": mcrmse,\n",
        "    }\n",
        "\n",
        "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
        "\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "\n",
        "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
        "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
        "\n",
        "    return (content_score + wording_score)/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UIPJBy8xQz7"
      },
      "source": [
        "## Model (regression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiFPjF04Z6E3"
      },
      "source": [
        "## class Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TLY3rXKUxROc"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "    def __init__(self,\n",
        "                model_config : dict,\n",
        "                model_dir: str,\n",
        "                target: str\n",
        "                ):\n",
        "        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"text\"]\n",
        "\n",
        "        self.input_col = \"prompt_train_ft_\" + target\n",
        "        self.text_cols = [self.input_col]\n",
        "        self.target = target\n",
        "        self.target_cols = [target]\n",
        "\n",
        "        self.model_config = model_config\n",
        "        self.model_name = model_config['model_name']\n",
        "        self.model_dir = model_dir\n",
        "\n",
        "        self.base_model        = model_config['base_model']['model']\n",
        "        self.base_tokenizer    = model_config['base_model']['tokenizer']\n",
        "        self.base_model_config = model_config['base_model']['config']\n",
        "\n",
        "        seed_everything(seed=42)\n",
        "\n",
        "        from transformers import DataCollatorWithPadding\n",
        "\n",
        "        self.data_collator = DataCollatorWithPadding(\n",
        "            tokenizer=self.base_tokenizer\n",
        "        )\n",
        "\n",
        "    def train_tokenize(self, examples: pd.DataFrame):\n",
        "      labels = [examples[self.target]]\n",
        "      tokenized = self.base_tokenizer(examples[self.input_col],\n",
        "                      padding=False,\n",
        "                      truncation=True,\n",
        "                      max_length=self.max_length)\n",
        "      return {\n",
        "            **tokenized,\n",
        "            \"labels\": labels,\n",
        "      }\n",
        "\n",
        "    def test_tokenize(self, examples: pd.DataFrame):\n",
        "        tokenized = self.base_tokenizer(examples[self.input_col],\n",
        "                        padding=False,\n",
        "                        truncation=True,\n",
        "                        max_length=self.max_length)\n",
        "        return tokenized\n",
        "\n",
        "\n",
        "    def train(self,\n",
        "            fold: int,\n",
        "            train_df: pd.DataFrame,\n",
        "            valid_df: pd.DataFrame,\n",
        "            model_config : dict\n",
        "        ) -> None:\n",
        "        \"\"\"fine-tuning\"\"\"\n",
        "\n",
        "        import pandas as pd\n",
        "        from datasets import Dataset, load_dataset, load_from_disk\n",
        "        from transformers import TrainingArguments, Trainer\n",
        "\n",
        "        optim =  model_config['sft']['optim']\n",
        "        lr_scheduler_type =  model_config['sft']['lr_scheduler_type']\n",
        "        learning_rate =  model_config['sft']['learning_rate']\n",
        "        per_device_train_batch_size =  model_config['sft']['per_device_train_batch_size']\n",
        "        gradient_accumulation_steps = model_config['sft']['gradient_accumulation_steps']\n",
        "        max_grad_norm = model_config['sft']['max_grad_norm']\n",
        "        warmup_ratio  = model_config['sft']['warmup_ratio']\n",
        "\n",
        "\n",
        "        save_steps =  model_config['sft']['save_steps']\n",
        "        max_steps = model_config['sft']['max_steps']\n",
        "        logging_steps = model_config['sft']['logging_steps']\n",
        "\n",
        "\n",
        "        max_seq_length = model_config['sft']['max_seq_length']\n",
        "\n",
        "        train_df = train_df[[self.input_col]]\n",
        "        valid_df = valid_df[[self.input_col]]\n",
        "\n",
        "        train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
        "        val_dataset = Dataset.from_pandas(valid_df, preserve_index=False)\n",
        "\n",
        "        lora_alpha = 16\n",
        "        lora_dropout = 0.1\n",
        "        lora_r = 64\n",
        "\n",
        "        peft_config = LoraConfig(\n",
        "            lora_alpha=lora_alpha,\n",
        "            lora_dropout=lora_dropout,\n",
        "            r=lora_r,\n",
        "            bias=\"none\",\n",
        "            task_type=\"CAUSAL_LM\"\n",
        "        )\n",
        "\n",
        "        # https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=self.model_dir,\n",
        "            optim=optim,\n",
        "            lr_scheduler_type=lr_scheduler_type,\n",
        "            learning_rate=learning_rate,\n",
        "            per_device_train_batch_size=per_device_train_batch_size,\n",
        "            gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "            save_steps=save_steps,\n",
        "            logging_steps=logging_steps,\n",
        "            fp16=True,\n",
        "            max_grad_norm=max_grad_norm,\n",
        "            max_steps=max_steps,\n",
        "            warmup_ratio=warmup_ratio,\n",
        "            group_by_length=True,\n",
        "\n",
        "        )\n",
        "\n",
        "        # prepare model for training\n",
        "        self.base_model = prepare_model_for_kbit_training(self.base_model)\n",
        "        self.base_model = get_peft_model(self.base_model, peft_config)\n",
        "\n",
        "        trainer = SFTTrainer(\n",
        "            model=self.base_model,\n",
        "            train_dataset=train_dataset,\n",
        "            peft_config=peft_config,\n",
        "            dataset_text_field = self.input_col,\n",
        "            max_seq_length = max_seq_length,\n",
        "            tokenizer=self.base_tokenizer,\n",
        "            args=training_args\n",
        "        )\n",
        "\n",
        "        # for name, module in trainer.model.named_modules():\n",
        "        #   if \"norm\" in name:\n",
        "        #       module = module.to(torch.float32)\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        output_dir = os.path.join(self.model_dir, \"finetuned\")\n",
        "        trainer.model.save_pretrained(output_dir)\n",
        "\n",
        "        self.base_tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        # Free memory for merging weights\n",
        "        del trainer\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    # def predict(self,\n",
        "    #             test_df: pd.DataFrame,\n",
        "    #             fold: int,\n",
        "    #             ):\n",
        "    #     \"\"\"predict content score\"\"\"\n",
        "\n",
        "    #     from datasets import Dataset, load_dataset, load_from_disk\n",
        "    #     from transformers import TrainingArguments, Trainer\n",
        "\n",
        "    #     sep = self.base_tokenizer.sep_token\n",
        "\n",
        "    #     in_text = (\n",
        "    #                 test_df[\"prompt_title\"] + sep\n",
        "    #                 + test_df[\"prompt_question\"] + sep\n",
        "    #                 + test_df[\"text\"]\n",
        "    #               )\n",
        "    #     test_df[self.input_col] = in_text\n",
        "\n",
        "    #     test_ = test_df[[self.input_col]]\n",
        "\n",
        "    #     test_dataset = Dataset.from_pandas(test_, preserve_index=False)\n",
        "    #     test_tokenized_dataset = test_dataset.map(self.test_tokenize, batched=False)\n",
        "\n",
        "    #     model_content = AutoModelForSequenceClassification.from_pretrained(f\"{self.model_dir}\")\n",
        "    #     model_content.eval()\n",
        "\n",
        "    #     # e.g. \"bert/fold_0/\"\n",
        "    #     model_fold_dir = os.path.join(self.model_dir, str(fold))\n",
        "\n",
        "    #     test_args = TrainingArguments(\n",
        "    #         output_dir=self.model_dir,\n",
        "    #         do_train = False,\n",
        "    #         do_predict = True,\n",
        "    #         per_device_eval_batch_size = 4,\n",
        "    #         dataloader_drop_last = False,\n",
        "    #     )\n",
        "\n",
        "    #     # init trainer\n",
        "    #     infer_content = Trainer(\n",
        "    #                   model = model_content,\n",
        "    #                   tokenizer=self.base_tokenizer,\n",
        "    #                   data_collator=self.data_collator,\n",
        "    #                   args = test_args)\n",
        "\n",
        "    #     preds = infer_content.predict(test_tokenized_dataset)[0]\n",
        "\n",
        "    #     return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict 1 (Development)"
      ],
      "metadata": {
        "id": "Dt1j6doe1pw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from peft import AutoPeftModelForCausalLM\n",
        "\n",
        "# output_dir = os.path.join(SYS_PROJECT_DIR,\"model/content/meta-llama_Llama-2-7b-chat-hf/fold_0/finetuned\")\n",
        "# model = AutoPeftModelForCausalLM.from_pretrained(output_dir, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
        "# # model = AutoPeftModelForCausalLM.from_pretrained(output_dir, device_map=\"auto\", torch_dtype=torch.float16)\n",
        "# model = model.merge_and_unload()"
      ],
      "metadata": {
        "id": "pb2D0jZTjHKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text = str(test.iloc[0]['prompt_ft_content'])\n",
        "# inputs = base_model_tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
        "# outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"),\n",
        "#                          attention_mask=inputs[\"attention_mask\"],\n",
        "#                          max_new_tokens=50, pad_token_id=base_model_tokenizer.eos_token_id)\n",
        "# pred = base_model_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "# print(pred)\n",
        "\n",
        "\n",
        "# # output_merged_dir = os.path.join(output_dir,\"finetuned_final\")\n",
        "# # model.save_pretrained(output_merged_dir, safe_serialization=True)\n",
        "\n",
        "# # base_tokenizer.save_pretrained(output_merged_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "P6Q8ElmFacYE",
        "outputId": "36047226-308e-4098-e7d7-676d8a02fe65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-10696ccf71f7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prompt_ft_content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), \n\u001b[0m\u001b[1;32m      4\u001b[0m                          \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          max_new_tokens=50, pad_token_id=base_model_tokenizer.eos_token_id)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1643\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m             \u001b[0;31m# sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2760\u001b[0;31m             \u001b[0mnext_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2762\u001b[0m             \u001b[0;31m# finished sentences should have their next token be a padding token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: probability tensor contains either `inf`, `nan` or element < 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from peft import get_peft_model\n",
        "import torch\n",
        "import transformers\n",
        "from peft import LoraConfig\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "output_dir = os.path.join(SYS_PROJECT_DIR,\"model/content/meta-llama_Llama-2-7b-chat-hf/fold_0/finetuned\")\n",
        "# output_dir = os.path.join(SYS_PROJECT_DIR,\"model/content/meta-llama_Llama-2-7b-chat-hf/fold_1/finetuned\")\n",
        "\n",
        "lora_config = LoraConfig.from_pretrained(output_dir)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    lora_config.base_model_name_or_path,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8ac15a655f6a4e85a837349969492c63",
            "440de2af5dd34c4f912e1b8e2afc5aa7",
            "54b35602551848b195500ce91ad17164",
            "669b80dcb4964b3b837b75d167264475",
            "cef9e44568ff4c169f0e35effffc6ba8",
            "85fd4da9b291481a9b11b899636316b4",
            "8a05753073e7408b883e5771297fd6b1",
            "9b6b8b9057ac46ff93c578f6249034fe",
            "674bd27442a84845a5ff9ef216313d9b",
            "b2640b25edf9453c8bb10237895bb881",
            "375f8d03a0cd4b89ba608ec220f22983"
          ]
        },
        "id": "p8aQGw77szdd",
        "outputId": "ceaa7453-6866-44fe-b6c8-b9bdba4efe65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ac15a655f6a4e85a837349969492c63"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "og9lV3f0tBaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = str(train.iloc[1]['prompt_test_ft_content'])\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", return_token_type_ids=False).to(\"cuda:0\")\n",
        "outputs = model.generate(**inputs, max_new_tokens=20)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "print(train.iloc[1]['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h6ngIvavDKi",
        "outputId": "c50d6092-1c7d-4c4f-8eaf-97bd6d900845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Instruction:\n",
            "Learn relationship between prompt_text , prompt_question and text to score.\n",
            "Score expresses how well answer_text matches prompt_text based on prompt_text.\n",
            "\n",
            "        ### Input:\n",
            "        prompt_text:\n",
            "        Background \r\n",
            "The Third Wave experiment took place at Cubberley High School in Palo Alto, California during the first week of April 1967. History teacher Ron Jones, finding himself unable to explain to his students how people throughout history followed the crowd even when terrible things were happening, decided to demonstrate it to his students through an experiment. Jones announced that he was starting a movement aimed to eliminate democracy. Jones named the movement The Third Wave as a symbol of strength, referring to the mythical belief that the third in a series of waves is the strongest. One of the central points of this movement was that democracys main weakness is that it favors the individual over the whole community. Jones emphasized this main point of the movement when he created this catchy motto: Strength through discipline, strength through community, strength through action, strength through pride. \r\n",
            "The Experiment \r\n",
            "Jones started the first day of the experiment emphasizing simple things like proper seating, and drilled the students extensively until they got it right. He then proceeded to enforce strict classroom discipline by emerging as an authoritarian figure. This resulted in dramatic improvements to the efficiency, or orderliness, of the class.  The first days session ended with only a few rules. Jones intended it to be a one-day experiment. Students had to be sitting at attention before the second bell, had to stand up to ask or answer questions and had to do it in three words or fewer, and were required to preface each remark with Mr. Jones. As the week went on, Jones class transformed into a group with a supreme sense of discipline and community. Jones made up a salute resembling that of the Nazi regime and ordered class members to salute each other even outside the class. They all obeyed this command. \r\n",
            "After only three days, the experiment took on a life of its own, with students from all over the school joining in. The class expanded from initial 30 students to 43 attendees. All of the students showed drastic improvement in their academic skills and tremendous motivation. All of the students were issued a member card and each of them received a special assignment, like designing a Third Wave Banner, stopping non-members from entering the class, or other tasks to bring honor to the movement. Jones instructed the students on how to initiate new members, and by the end of the day the movement had over 200 participants. Jones was surprised that some of the students started reporting to him when other members of the movement failed to abide by the rules. \r\n",
            "By the fourth day of the experiment, the students became increasingly involved in the project and their discipline and loyalty to the project was so outstanding that Jones felt it was slipping out of control. He decided to terminate the movement, so he lied to students by announcing that the Third Wave was a part of a nationwide movement and that on the next day a presidential candidate of the movement would publicly announce its existence on television. Jones ordered students to attend a noon rally on Friday to witness the announcement. \r\n",
            "At the end of the week, instead of a televised address of their leader, the students were presented with a blank channel. After a few minutes of waiting, Jones announced that they had been a part of an experiment to demonstrate how people willingly create a sense of superiority over others, and how this can lead people to justify doing horrible things in the name of the states honor.\n",
            "        prompt_question:\n",
            "        Summarize how the Third Wave developed over such a short period of time and why the experiment was ended.\n",
            "        answer_text:\n",
            "        The Third Wave developed  rapidly because the students genuinly believed that it was the best course of action. Their grades, acomplishments, and classparticipation/ behavior had improved dramatically since the experiment began. There did not seem to be any consiquenses in the students eyes. They became extremely engaged in all the Third Wave activites both inside and outside tha classroom. The experiment ended because the students were so patriotic about the \"movement\". The history class of thirty rapidly grew to 200 in three days.  That means 170 students joined a school \"movement\" in two days. Thats 85 people per day! On the fifth and final day all the students had completley believed that the \"Third Wave\" was a movement that would expell democracy. They believed a candidate from the \"movement\" would anounce its existance on television after five days of its success. The creater, Ron Jones, believed it had gone too far and for everyone's safety he shut it down.  If he hadn't the fake organization would have grown into something out of his controll. The Third Wave only lasted for a week. It could have spiralled into the American version of the Nazi Party, which is the opposite of what America stands for.\n",
            "\n",
            "        ### Response:\n",
            "        Output score here\n",
            "        10/10\n",
            "        Explanation:\n",
            "        The answer text provides a clear and\n",
            "3.27289414977436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[train.content < -1.70]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "SWH7Hy1s4K-G",
        "outputId": "cbfc80d1-323a-4905-a178-16ae04076b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        student_id prompt_id  \\\n",
              "406   60839fab23ed    814d6b   \n",
              "3792  563eeb57f8dd    3b9047   \n",
              "6146  7da60289bd4c    39c16e   \n",
              "7153  fe705879b87c    39c16e   \n",
              "\n",
              "                                                   text   content   wording  \\\n",
              "406   History Teacher Ron Jones couldn't control his... -1.729859 -0.362702   \n",
              "3792  The structure of egyptans made a ruler called ... -1.729859 -0.362702   \n",
              "6146  A tragedy can both be a good and bad thing, it... -1.729859 -0.362702   \n",
              "7153  Misfortune, great error or frailty, and dead a... -1.729859 -0.362702   \n",
              "\n",
              "                                        prompt_question  \\\n",
              "406   Summarize how the Third Wave developed over su...   \n",
              "3792  In complete sentences, summarize the structure...   \n",
              "6146  Summarize at least 3 elements of an ideal trag...   \n",
              "7153  Summarize at least 3 elements of an ideal trag...   \n",
              "\n",
              "                   prompt_title  \\\n",
              "406              The Third Wave   \n",
              "3792  Egyptian Social Structure   \n",
              "6146                 On Tragedy   \n",
              "7153                 On Tragedy   \n",
              "\n",
              "                                            prompt_text  \\\n",
              "406   Background \\r\\nThe Third Wave experiment took ...   \n",
              "3792  Egyptian society was structured like a pyramid...   \n",
              "6146  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
              "7153  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
              "\n",
              "                                      prompt_ft_content  \\\n",
              "406   \\n\\n        ### Instruction:\\n        Learn re...   \n",
              "3792  \\n\\n        ### Instruction:\\n        Learn re...   \n",
              "6146  \\n\\n        ### Instruction:\\n        Learn re...   \n",
              "7153  \\n\\n        ### Instruction:\\n        Learn re...   \n",
              "\n",
              "                                      prompt_ft_wording  fold  \\\n",
              "406   \\n\\n        ### Instruction:\\n        Learn re...   0.0   \n",
              "3792  \\n\\n        ### Instruction:\\n        Learn re...   1.0   \n",
              "6146  \\n\\n        ### Instruction:\\n        Learn re...   0.0   \n",
              "7153  \\n\\n        ### Instruction:\\n        Learn re...   0.0   \n",
              "\n",
              "                                prompt_train_ft_content  \\\n",
              "406   \\n### Instruction:\\nLearn relationship between...   \n",
              "3792  \\n### Instruction:\\nLearn relationship between...   \n",
              "6146  \\n### Instruction:\\nLearn relationship between...   \n",
              "7153  \\n### Instruction:\\nLearn relationship between...   \n",
              "\n",
              "                                prompt_train_ft_wording  \\\n",
              "406   \\n### Instruction:\\nLearn relationship between...   \n",
              "3792  \\n### Instruction:\\nLearn relationship between...   \n",
              "6146  \\n### Instruction:\\nLearn relationship between...   \n",
              "7153  \\n### Instruction:\\nLearn relationship between...   \n",
              "\n",
              "                                 prompt_test_ft_content  \\\n",
              "406   \\n### Instruction:\\nLearn relationship between...   \n",
              "3792  \\n### Instruction:\\nLearn relationship between...   \n",
              "6146  \\n### Instruction:\\nLearn relationship between...   \n",
              "7153  \\n### Instruction:\\nLearn relationship between...   \n",
              "\n",
              "                                 prompt_test_ft_wording  \n",
              "406   \\n### Instruction:\\nLearn relationship between...  \n",
              "3792  \\n### Instruction:\\nLearn relationship between...  \n",
              "6146  \\n### Instruction:\\nLearn relationship between...  \n",
              "7153  \\n### Instruction:\\nLearn relationship between...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6a8c99b-a9cb-4b24-9a50-32f6498f7cd2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "      <th>prompt_ft_content</th>\n",
              "      <th>prompt_ft_wording</th>\n",
              "      <th>fold</th>\n",
              "      <th>prompt_train_ft_content</th>\n",
              "      <th>prompt_train_ft_wording</th>\n",
              "      <th>prompt_test_ft_content</th>\n",
              "      <th>prompt_test_ft_wording</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>60839fab23ed</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>History Teacher Ron Jones couldn't control his...</td>\n",
              "      <td>-1.729859</td>\n",
              "      <td>-0.362702</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>\\n\\n        ### Instruction:\\n        Learn re...</td>\n",
              "      <td>\\n\\n        ### Instruction:\\n        Learn re...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3792</th>\n",
              "      <td>563eeb57f8dd</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>The structure of egyptans made a ruler called ...</td>\n",
              "      <td>-1.729859</td>\n",
              "      <td>-0.362702</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>\\n\\n        ### Instruction:\\n        Learn re...</td>\n",
              "      <td>\\n\\n        ### Instruction:\\n        Learn re...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6146</th>\n",
              "      <td>7da60289bd4c</td>\n",
              "      <td>39c16e</td>\n",
              "      <td>A tragedy can both be a good and bad thing, it...</td>\n",
              "      <td>-1.729859</td>\n",
              "      <td>-0.362702</td>\n",
              "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
              "      <td>On Tragedy</td>\n",
              "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
              "      <td>\\n\\n        ### Instruction:\\n        Learn re...</td>\n",
              "      <td>\\n\\n        ### Instruction:\\n        Learn re...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7153</th>\n",
              "      <td>fe705879b87c</td>\n",
              "      <td>39c16e</td>\n",
              "      <td>Misfortune, great error or frailty, and dead a...</td>\n",
              "      <td>-1.729859</td>\n",
              "      <td>-0.362702</td>\n",
              "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
              "      <td>On Tragedy</td>\n",
              "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
              "      <td>\\n\\n        ### Instruction:\\n        Learn re...</td>\n",
              "      <td>\\n\\n        ### Instruction:\\n        Learn re...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6a8c99b-a9cb-4b24-9a50-32f6498f7cd2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6a8c99b-a9cb-4b24-9a50-32f6498f7cd2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6a8c99b-a9cb-4b24-9a50-32f6498f7cd2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict 2 (Development)"
      ],
      "metadata": {
        "id": "Utk7LocU2OvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "output_dir = os.path.join(SYS_PROJECT_DIR,\"model/content/meta-llama_Llama-2-7b-chat-hf/fold_0/finetuned\")\n",
        "output_dir = os.path.join(SYS_PROJECT_DIR,\"model/content/meta-llama_Llama-2-7b-chat-hf/fold_1/finetuned\")\n",
        "\n",
        "# load base LLM model and tokenizer\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    output_dir,\n",
        "    low_cpu_mem_usage=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Merge LoRA and base model\n",
        "# merged_model = model.merge_and_unload()\n",
        "\n",
        "# Save the merged model\n",
        "final_output_dir = os.path.join(output_dir, \"final\")\n",
        "model.save_pretrained(final_output_dir,safe_serialization=True)\n",
        "tokenizer.save_pretrained(final_output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "79878dfd4f074ef2ab74cbea6f29537e",
            "63452e82f1314f629004d7946606c051",
            "d9ea08ec188445009a9f6d661eee01d7",
            "253008ff076246b4b6f49cffcbbb6742",
            "c6fc5bcd701b4bca9430e9a75f69e584",
            "a0eb62e403be4b4fa799c9e6968313e0",
            "a59469f542ed48b98a181cb4d609f371",
            "b156f03e576e481fb47d14e6eecba7d8",
            "01bfc2ce68214c548c468f8ae75a3b97",
            "dca859c89af942fd862a0a9ba4b99bd0",
            "6282d1bae8b549be8cc100cda1414cb0"
          ]
        },
        "id": "rTuJPgBa4K1J",
        "outputId": "acb04274-6f52-4136-eb3d-ed86698a04b3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79878dfd4f074ef2ab74cbea6f29537e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/gdrive/MyDrive/Colab Notebooks/CommonLit/V2/model/content/meta-llama_Llama-2-7b-chat-hf/fold_1/finetuned/final/tokenizer_config.json',\n",
              " '/content/gdrive/MyDrive/Colab Notebooks/CommonLit/V2/model/content/meta-llama_Llama-2-7b-chat-hf/fold_1/finetuned/final/special_tokens_map.json',\n",
              " '/content/gdrive/MyDrive/Colab Notebooks/CommonLit/V2/model/content/meta-llama_Llama-2-7b-chat-hf/fold_1/finetuned/final/tokenizer.model',\n",
              " '/content/gdrive/MyDrive/Colab Notebooks/CommonLit/V2/model/content/meta-llama_Llama-2-7b-chat-hf/fold_1/finetuned/final/added_tokens.json',\n",
              " '/content/gdrive/MyDrive/Colab Notebooks/CommonLit/V2/model/content/meta-llama_Llama-2-7b-chat-hf/fold_1/finetuned/final/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load base LLM model and tokenizer\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    final_output_dir,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "F_gaNcFS5VRc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fdaf64ecf83b4776817ecfb40f2cecca",
            "2d013fe00af34e24acea8dfa7464ae30",
            "8fbdb690805f49f9a638e11dd35767d1",
            "e26f9958e47f4780b56a434359cccac8",
            "0bbd85c681dc465c8c999ab8e79d4b7a",
            "ab0f074dd9b44b61928671634d0f6f88",
            "56cca52cec0f42159051013a1da252b3",
            "638b611796a644c88efc0047f21827c8",
            "6e42ceb465fa4d9c87e149805b3bf29e",
            "c61fbe85ac994a179a12d3f3f1470b46",
            "58b7d2900bb444309c42481f9f8a22fd"
          ]
        },
        "outputId": "407b5ffc-73df-432c-b9d8-c501e7f4214e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdaf64ecf83b4776817ecfb40f2cecca"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = str(train.iloc[0]['prompt_test_ft_content'])\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", return_token_type_ids=False).to(\"cuda:0\")\n",
        "outputs = model.generate(**inputs, max_new_tokens=20)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "print(train.iloc[0]['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "YKvErcXu5iqr",
        "outputId": "27db8708-7bd1-4407-c729-a4b77b598a5e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1529: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cuda, whereas the model is on cpu. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cpu') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-2d4c994522a6>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prompt_test_ft_content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_token_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_prepare_inputs_for_generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1643\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2724\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2725\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m    810\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;31m# embed positions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2208\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def predict(self,\n",
        "#                 test_df: pd.DataFrame,\n",
        "#                 fold: int,\n",
        "#                 ):\n",
        "#         \"\"\"predict content score\"\"\"\n",
        "\n",
        "#         from datasets import Dataset, load_dataset, load_from_disk\n",
        "#         from transformers import TrainingArguments, Trainer\n",
        "\n",
        "#         in_text = (\n",
        "#                     test_df[\"prompt_title\"] + sep\n",
        "#                     + test_df[\"prompt_question\"] + sep\n",
        "#                     + test_df[\"text\"]\n",
        "#                   )\n",
        "#         test_df[self.input_col] = in_text\n",
        "\n",
        "#         test_ = test_df[[self.input_col]]\n",
        "\n",
        "#         lora_config = LoraConfig.from_pretrained(f\"{self.model_dir}\")\n",
        "#         model = get_peft_model(model, lora_config)\n",
        "\n",
        "#         # e.g. \"bert/fold_0/\"\n",
        "#         model_fold_dir = os.path.join(self.model_dir, str(fold))\n",
        "\n",
        "#         device = \"cuda:1\"\n",
        "#         inputs = tokenizer(prompt_for_inference,\n",
        "#                           return_tensors=\"pt\").to(device)\n",
        "\n",
        "#         preds = infer_content.predict(test_tokenized_dataset)[0]\n",
        "\n",
        "#         return preds"
      ],
      "metadata": {
        "id": "6KQo7RcbW4bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IGKfDn6AjUG"
      },
      "source": [
        "## ############################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuJIWCURaOK1"
      },
      "source": [
        "## train_by_fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5KPPj5aTpvb"
      },
      "outputs": [],
      "source": [
        "def train_by_fold(\n",
        "        train_df: pd.DataFrame,\n",
        "        target:str,\n",
        "        model_config: dict\n",
        "    ):\n",
        "\n",
        "    model_root_dir = model_config['model_root_dir']\n",
        "    model_name = model_config['model_name']\n",
        "    n_splits   = model_config['n_splits']\n",
        "\n",
        "    for fold in range(Model_Config['n_splits']):\n",
        "        print(f\"fold {fold}:\")\n",
        "\n",
        "        train_data = train_df[train_df[\"fold\"] != fold]\n",
        "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
        "\n",
        "        model_dir =  os.path.join(SYS_PROJECT_DIR, model_root_dir, f\"{target}/{model_name}/fold_{fold}\")\n",
        "\n",
        "        if os.path.exists(model_dir):\n",
        "          shutil.rmtree(model_dir)\n",
        "\n",
        "        model = Model(\n",
        "            model_config=model_config,\n",
        "            model_dir = model_dir,\n",
        "            target=target\n",
        "           )\n",
        "\n",
        "        model.train(\n",
        "            fold=fold,\n",
        "            train_df=train_data,\n",
        "            valid_df=valid_data,\n",
        "            model_config = model_config\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAce_XWwagfr"
      },
      "source": [
        "## Run train_by_fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395,
          "referenced_widgets": [
            "cdd239e29e2e468d9d8a7975a0f66bcf",
            "4f3ab1b8663441e1a6a6978b2206dd09",
            "7ed1b6eea1ac4f86b09a97ce8152f2ad",
            "bab3459c8f2249f2b6dd652277887f4d",
            "f5f34e6534474cf0a1711e3f2e5244fe",
            "eaf78d8607384b448240f215bb35d6a5",
            "d846bdfe07634507bd7e7763954cb574",
            "de2fe3b4af704a5b8310fc0a5762f072",
            "e878f9a05d1d45d48df3b277ad53027c",
            "a03176a2fd654572870d8148da0b8490",
            "84577ebc3716498096cc11c9755645b7",
            "b7d368d29a484124b17d372840be401e",
            "50f00afc76694e128950b90b44b81022",
            "e45eb53bbea14368aa881072c2111354",
            "4770778950a546479f7e68c0890f3303",
            "84b3ed4d43a24feabb236f93f8ac026a",
            "1f9b029fad5146588892dd3b9a74a41b",
            "87cb15e702474ecb8722ce59ce960afa",
            "bc0e80889fc44aac8c3364f55d9912a8",
            "32d5a4754bcb4f6d98529f68648445ae",
            "cf6f493d3ae94ab28e12c2587bf30f4e",
            "939ba9c303ef407d9462b1b4e7cc7fcc"
          ]
        },
        "id": "x9S248biVNuz",
        "outputId": "c967ac8f-bb2c-4416-8a91-dbb369677c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4005 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdd239e29e2e468d9d8a7975a0f66bcf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:40, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.158400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3160 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7d368d29a484124b17d372840be401e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:40, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.108000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.738300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# for target in [\"content\", \"wording\"]:\n",
        "for target in [\"content\"]:\n",
        "    train_by_fold(\n",
        "        train,\n",
        "        target=target,\n",
        "        model_config = Model_Config\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ovIyUoZY_wKx",
        "outputId": "b6eb045e-7619-4cd6-9a74-5ef9f1f27061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        student_id prompt_id  \\\n",
              "0     000e8c3c7ddb    814d6b   \n",
              "1     0070c9e7af47    814d6b   \n",
              "2     0095993991fe    814d6b   \n",
              "3     00c20c6ddd23    814d6b   \n",
              "4     00d40ad10dc9    814d6b   \n",
              "...            ...       ...   \n",
              "7160  fef3e85236e5    39c16e   \n",
              "7161  ff0f65eecf02    39c16e   \n",
              "7162  ff186473ea0a    39c16e   \n",
              "7163  ff5e9e6068da    39c16e   \n",
              "7164  ffe4a98093b2    39c16e   \n",
              "\n",
              "                                                   text   content   wording  \\\n",
              "0     The third wave was an experimentto see how peo...  0.205683  0.380538   \n",
              "1     The Third Wave developed  rapidly because the ...  3.272894  3.219757   \n",
              "2     The third wave only started as an experiment w...  0.205683  0.380538   \n",
              "3     The experimen was orginally about how even whe...  0.567975  0.969062   \n",
              "4     The third wave developed so quickly due to the... -0.910596 -0.081769   \n",
              "...                                                 ...       ...       ...   \n",
              "7160  It has to be made on a complex storyline, with... -0.981265 -1.548900   \n",
              "7161  Aristotle descirbes an ideal tradgedy as being... -0.511077 -1.589115   \n",
              "7162  A tragedy should have a complex plan not a sim... -0.834946 -0.593749   \n",
              "7163  Aristotle believed that the ideal tradegy shou... -0.157460 -0.165811   \n",
              "7164  An ideal tragety has three elements that make ... -0.393310  0.627128   \n",
              "\n",
              "                                        prompt_question    prompt_title  \\\n",
              "0     Summarize how the Third Wave developed over su...  The Third Wave   \n",
              "1     Summarize how the Third Wave developed over su...  The Third Wave   \n",
              "2     Summarize how the Third Wave developed over su...  The Third Wave   \n",
              "3     Summarize how the Third Wave developed over su...  The Third Wave   \n",
              "4     Summarize how the Third Wave developed over su...  The Third Wave   \n",
              "...                                                 ...             ...   \n",
              "7160  Summarize at least 3 elements of an ideal trag...      On Tragedy   \n",
              "7161  Summarize at least 3 elements of an ideal trag...      On Tragedy   \n",
              "7162  Summarize at least 3 elements of an ideal trag...      On Tragedy   \n",
              "7163  Summarize at least 3 elements of an ideal trag...      On Tragedy   \n",
              "7164  Summarize at least 3 elements of an ideal trag...      On Tragedy   \n",
              "\n",
              "                                            prompt_text  \\\n",
              "0     Background \\r\\nThe Third Wave experiment took ...   \n",
              "1     Background \\r\\nThe Third Wave experiment took ...   \n",
              "2     Background \\r\\nThe Third Wave experiment took ...   \n",
              "3     Background \\r\\nThe Third Wave experiment took ...   \n",
              "4     Background \\r\\nThe Third Wave experiment took ...   \n",
              "...                                                 ...   \n",
              "7160  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
              "7161  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
              "7162  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
              "7163  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
              "7164  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
              "\n",
              "                                prompt_train_ft_content  \\\n",
              "0     \\n### Instruction:\\nLearn relationship between...   \n",
              "1     \\n### Instruction:\\nLearn relationship between...   \n",
              "2     \\n### Instruction:\\nLearn relationship between...   \n",
              "3     \\n### Instruction:\\nLearn relationship between...   \n",
              "4     \\n### Instruction:\\nLearn relationship between...   \n",
              "...                                                 ...   \n",
              "7160  \\n### Instruction:\\nLearn relationship between...   \n",
              "7161  \\n### Instruction:\\nLearn relationship between...   \n",
              "7162  \\n### Instruction:\\nLearn relationship between...   \n",
              "7163  \\n### Instruction:\\nLearn relationship between...   \n",
              "7164  \\n### Instruction:\\nLearn relationship between...   \n",
              "\n",
              "                                prompt_train_ft_wording  \\\n",
              "0     \\n### Instruction:\\nLearn relationship between...   \n",
              "1     \\n### Instruction:\\nLearn relationship between...   \n",
              "2     \\n### Instruction:\\nLearn relationship between...   \n",
              "3     \\n### Instruction:\\nLearn relationship between...   \n",
              "4     \\n### Instruction:\\nLearn relationship between...   \n",
              "...                                                 ...   \n",
              "7160  \\n### Instruction:\\nLearn relationship between...   \n",
              "7161  \\n### Instruction:\\nLearn relationship between...   \n",
              "7162  \\n### Instruction:\\nLearn relationship between...   \n",
              "7163  \\n### Instruction:\\nLearn relationship between...   \n",
              "7164  \\n### Instruction:\\nLearn relationship between...   \n",
              "\n",
              "                                 prompt_test_ft_content  \\\n",
              "0     \\n### Instruction:\\nLearn relationship between...   \n",
              "1     \\n### Instruction:\\nLearn relationship between...   \n",
              "2     \\n### Instruction:\\nLearn relationship between...   \n",
              "3     \\n### Instruction:\\nLearn relationship between...   \n",
              "4     \\n### Instruction:\\nLearn relationship between...   \n",
              "...                                                 ...   \n",
              "7160  \\n### Instruction:\\nLearn relationship between...   \n",
              "7161  \\n### Instruction:\\nLearn relationship between...   \n",
              "7162  \\n### Instruction:\\nLearn relationship between...   \n",
              "7163  \\n### Instruction:\\nLearn relationship between...   \n",
              "7164  \\n### Instruction:\\nLearn relationship between...   \n",
              "\n",
              "                                 prompt_test_ft_wording  fold  \n",
              "0     \\n### Instruction:\\nLearn relationship between...   0.0  \n",
              "1     \\n### Instruction:\\nLearn relationship between...   0.0  \n",
              "2     \\n### Instruction:\\nLearn relationship between...   0.0  \n",
              "3     \\n### Instruction:\\nLearn relationship between...   0.0  \n",
              "4     \\n### Instruction:\\nLearn relationship between...   0.0  \n",
              "...                                                 ...   ...  \n",
              "7160  \\n### Instruction:\\nLearn relationship between...   0.0  \n",
              "7161  \\n### Instruction:\\nLearn relationship between...   0.0  \n",
              "7162  \\n### Instruction:\\nLearn relationship between...   0.0  \n",
              "7163  \\n### Instruction:\\nLearn relationship between...   0.0  \n",
              "7164  \\n### Instruction:\\nLearn relationship between...   0.0  \n",
              "\n",
              "[7165 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5987b3c4-478f-4469-9e5b-582f186966db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "      <th>prompt_train_ft_content</th>\n",
              "      <th>prompt_train_ft_wording</th>\n",
              "      <th>prompt_test_ft_content</th>\n",
              "      <th>prompt_test_ft_wording</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000e8c3c7ddb</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave was an experimentto see how peo...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0070c9e7af47</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>3.272894</td>\n",
              "      <td>3.219757</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0095993991fe</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave only started as an experiment w...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00c20c6ddd23</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The experimen was orginally about how even whe...</td>\n",
              "      <td>0.567975</td>\n",
              "      <td>0.969062</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00d40ad10dc9</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave developed so quickly due to the...</td>\n",
              "      <td>-0.910596</td>\n",
              "      <td>-0.081769</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7160</th>\n",
              "      <td>fef3e85236e5</td>\n",
              "      <td>39c16e</td>\n",
              "      <td>It has to be made on a complex storyline, with...</td>\n",
              "      <td>-0.981265</td>\n",
              "      <td>-1.548900</td>\n",
              "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
              "      <td>On Tragedy</td>\n",
              "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7161</th>\n",
              "      <td>ff0f65eecf02</td>\n",
              "      <td>39c16e</td>\n",
              "      <td>Aristotle descirbes an ideal tradgedy as being...</td>\n",
              "      <td>-0.511077</td>\n",
              "      <td>-1.589115</td>\n",
              "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
              "      <td>On Tragedy</td>\n",
              "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7162</th>\n",
              "      <td>ff186473ea0a</td>\n",
              "      <td>39c16e</td>\n",
              "      <td>A tragedy should have a complex plan not a sim...</td>\n",
              "      <td>-0.834946</td>\n",
              "      <td>-0.593749</td>\n",
              "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
              "      <td>On Tragedy</td>\n",
              "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7163</th>\n",
              "      <td>ff5e9e6068da</td>\n",
              "      <td>39c16e</td>\n",
              "      <td>Aristotle believed that the ideal tradegy shou...</td>\n",
              "      <td>-0.157460</td>\n",
              "      <td>-0.165811</td>\n",
              "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
              "      <td>On Tragedy</td>\n",
              "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7164</th>\n",
              "      <td>ffe4a98093b2</td>\n",
              "      <td>39c16e</td>\n",
              "      <td>An ideal tragety has three elements that make ...</td>\n",
              "      <td>-0.393310</td>\n",
              "      <td>0.627128</td>\n",
              "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
              "      <td>On Tragedy</td>\n",
              "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>\\n### Instruction:\\nLearn relationship between...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7165 rows  13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5987b3c4-478f-4469-9e5b-582f186966db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5987b3c4-478f-4469-9e5b-582f186966db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5987b3c4-478f-4469-9e5b-582f186966db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2f110b13-9000-4db4-945b-46a06cd60b48\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f110b13-9000-4db4-945b-46a06cd60b48')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2f110b13-9000-4db4-945b-46a06cd60b48 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMFk6nVrDGnF"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TquUx9Jy9zn0"
      },
      "outputs": [],
      "source": [
        "def predict_train(\n",
        "    train_df: pd.DataFrame,\n",
        "    target:str,\n",
        "    model_config:dict\n",
        "    ) -> pd.DataFrame:\n",
        "    \"\"\"predict oof data\"\"\"\n",
        "\n",
        "    model_root_dir = model_config['model_root_dir']\n",
        "    model_name = model_config['model_name']\n",
        "    n_splits = model_config['n_splits']\n",
        "\n",
        "    for fold in range(n_splits):\n",
        "\n",
        "        print(f\"fold {fold}:\")\n",
        "\n",
        "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
        "\n",
        "        model_dir =  os.path.join(SYS_PROJECT_DIR, model_root_dir, f\"{target}/{model_name}/fold_{fold}\")\n",
        "\n",
        "        model = Model(\n",
        "            model_config = model_config,\n",
        "            model_dir = model_dir,\n",
        "            target=target\n",
        "           )\n",
        "\n",
        "        pred = model.predict(\n",
        "            test_df=valid_data,\n",
        "            fold=fold\n",
        "        )\n",
        "\n",
        "        train_df.loc[valid_data.index, f\"{target}_pred\"] = pred\n",
        "\n",
        "    return train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W08k_tdGS3c"
      },
      "outputs": [],
      "source": [
        "for target in [\"content\", \"wording\"]:\n",
        "\n",
        "  from sklearn.metrics import mean_squared_error\n",
        "\n",
        "  train = predict_train(\n",
        "        train.head(500),\n",
        "        target=target,\n",
        "        model_config = Model_Config\n",
        "    )\n",
        "  rmse = mean_squared_error(train[target], train[f\"{target}_pred\"], squared=False)\n",
        "  print(f\"cv {target} rmse: {rmse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxFiW6zbyIwJ"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewC9IJcJyfUN"
      },
      "outputs": [],
      "source": [
        "def predict_test(\n",
        "      test_df: pd.DataFrame,\n",
        "      target:str,\n",
        "      model_config:dict\n",
        "    ) -> pd.DataFrame:\n",
        "    \"\"\"predict using mean folds\"\"\"\n",
        "\n",
        "    model_root_dir = model_config['model_root_dir']\n",
        "    model_name = model_config['model_name']\n",
        "    n_splits = model_config['n_splits']\n",
        "\n",
        "    for fold in range(n_splits):\n",
        "        print(f\"fold {fold}:\")\n",
        "\n",
        "        model_dir =  os.path.join(SYS_PROJECT_DIR, model_root_dir, f\"{target}/{model_name}/fold_{fold}\")\n",
        "\n",
        "        model = Model(\n",
        "            model_config = model_config,\n",
        "            model_dir = model_dir,\n",
        "            target=target\n",
        "           )\n",
        "\n",
        "        pred = model.predict(\n",
        "            test_df=test_df,\n",
        "            fold=fold\n",
        "        )\n",
        "\n",
        "        test_df[f\"{target}_pred_{fold}\"] = pred\n",
        "\n",
        "    test_df[f\"{target}\"] = test_df[[f\"{target}_pred_{fold}\" for fold in range(n_splits)]].mean(axis=1)\n",
        "\n",
        "    return test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnmu7LGOyJMG"
      },
      "outputs": [],
      "source": [
        "for target in [\"content\", \"wording\"]:\n",
        "    test = predict_test(\n",
        "          test,\n",
        "          target=target,\n",
        "          model_config = Model_Config\n",
        "      )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZw9rUmD436n"
      },
      "source": [
        "# LGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRvIZE-jAKNa"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmNFcxhY4-Fp"
      },
      "outputs": [],
      "source": [
        "targets = [\"content\", \"wording\"]\n",
        "\n",
        "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\"\n",
        "               ] + targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nT32NS-AO1A"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn563umT58M8"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "n_splits = Model_Config['n_splits']\n",
        "\n",
        "model_dict = {}\n",
        "\n",
        "for target in targets:\n",
        "    models = []\n",
        "\n",
        "    for fold in range(n_splits):\n",
        "\n",
        "        X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
        "        y_train_cv = train[train[\"fold\"] != fold][target]\n",
        "\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
        "        dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
        "\n",
        "        params = {\n",
        "                  'boosting_type': 'gbdt', # gbdt\n",
        "                  'random_state': 42,\n",
        "                  'objective': 'regression',\n",
        "                  'metric': 'rmse',\n",
        "                  'learning_rate': 0.05,\n",
        "                  'min_child_samples' : 10\n",
        "                  }\n",
        "\n",
        "        evaluation_results = {}\n",
        "        model = lgb.train(params,\n",
        "                          num_boost_round=1000,\n",
        "                          #categorical_feature = categorical_features,\n",
        "                          valid_names=['train', 'valid'],\n",
        "                          train_set=dtrain,\n",
        "                          valid_sets=dval,\n",
        "                          callbacks=[\n",
        "                              lgb.early_stopping(stopping_rounds=10, verbose=True),\n",
        "                              lgb.log_evaluation(100),\n",
        "                              lgb.callback.record_evaluation(evaluation_results)\n",
        "                            ],\n",
        "                          )\n",
        "        models.append(model)\n",
        "\n",
        "    model_dict[target] = models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LII9GpilAVCp"
      },
      "source": [
        "## Evaluation (CV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHrpuhCPAZTx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "rmses = []\n",
        "\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "        # iloc\n",
        "        X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
        "        y_eval_cv = train[train[\"fold\"] == fold][target]\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "\n",
        "        trues.extend(y_eval_cv)\n",
        "        preds.extend(pred)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "    print(f\"{target}_rmse : {rmse}\")\n",
        "    rmses = rmses + [rmse]\n",
        "\n",
        "print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLoSFCodqv_I"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NZ0-tHJqwYm"
      },
      "outputs": [],
      "source": [
        "n_splits = Model_Config['n_splits']\n",
        "\n",
        "drop_columns = [\n",
        "                #\"fold\",\n",
        "                \"student_id\", \"prompt_id\", \"text\",\n",
        "                \"prompt_question\", \"prompt_title\",\n",
        "                \"prompt_text\",\n",
        "                \"input\"\n",
        "               ] + [\n",
        "                f\"content_pred_{i}\" for i in range(n_splits)\n",
        "                ] + [\n",
        "                f\"wording_pred_{i}\" for i in range(n_splits)\n",
        "                ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2shew8Rq8HV"
      },
      "outputs": [],
      "source": [
        "pred_dict = {}\n",
        "for target in targets:\n",
        "    models = model_dict[target]\n",
        "    preds = []\n",
        "\n",
        "    for fold, model in enumerate(models):\n",
        "        X_eval_cv = test.drop(columns=drop_columns)\n",
        "\n",
        "        pred = model.predict(X_eval_cv)\n",
        "        preds.append(pred)\n",
        "\n",
        "    pred_dict[target] = preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E8WvkUArGt6"
      },
      "outputs": [],
      "source": [
        "for target in targets:\n",
        "    preds = pred_dict[target]\n",
        "    for i, pred in enumerate(preds):\n",
        "        test[f\"{target}_pred_{i}\"] = pred\n",
        "\n",
        "    test[target] = test[[f\"{target}_pred_{fold}\" for fold in range(n_splits)]].mean(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRxNPglyrXVl"
      },
      "outputs": [],
      "source": [
        "submission_file = os.path.join(SYS_OUTPUT_DIR, \"submission.csv\")\n",
        "test[[\"student_id\", \"content\", \"wording\"]].to_csv(submission_file, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPPDpIPoBJLp4YTNQSmDnVP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8ac15a655f6a4e85a837349969492c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_440de2af5dd34c4f912e1b8e2afc5aa7",
              "IPY_MODEL_54b35602551848b195500ce91ad17164",
              "IPY_MODEL_669b80dcb4964b3b837b75d167264475"
            ],
            "layout": "IPY_MODEL_cef9e44568ff4c169f0e35effffc6ba8"
          }
        },
        "440de2af5dd34c4f912e1b8e2afc5aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85fd4da9b291481a9b11b899636316b4",
            "placeholder": "",
            "style": "IPY_MODEL_8a05753073e7408b883e5771297fd6b1",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "54b35602551848b195500ce91ad17164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b6b8b9057ac46ff93c578f6249034fe",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_674bd27442a84845a5ff9ef216313d9b",
            "value": 3
          }
        },
        "669b80dcb4964b3b837b75d167264475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2640b25edf9453c8bb10237895bb881",
            "placeholder": "",
            "style": "IPY_MODEL_375f8d03a0cd4b89ba608ec220f22983",
            "value": " 3/3 [02:21&lt;00:00, 45.26s/it]"
          }
        },
        "cef9e44568ff4c169f0e35effffc6ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85fd4da9b291481a9b11b899636316b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a05753073e7408b883e5771297fd6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b6b8b9057ac46ff93c578f6249034fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "674bd27442a84845a5ff9ef216313d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2640b25edf9453c8bb10237895bb881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375f8d03a0cd4b89ba608ec220f22983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdd239e29e2e468d9d8a7975a0f66bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f3ab1b8663441e1a6a6978b2206dd09",
              "IPY_MODEL_7ed1b6eea1ac4f86b09a97ce8152f2ad",
              "IPY_MODEL_bab3459c8f2249f2b6dd652277887f4d"
            ],
            "layout": "IPY_MODEL_f5f34e6534474cf0a1711e3f2e5244fe"
          }
        },
        "4f3ab1b8663441e1a6a6978b2206dd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaf78d8607384b448240f215bb35d6a5",
            "placeholder": "",
            "style": "IPY_MODEL_d846bdfe07634507bd7e7763954cb574",
            "value": "Map: 100%"
          }
        },
        "7ed1b6eea1ac4f86b09a97ce8152f2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de2fe3b4af704a5b8310fc0a5762f072",
            "max": 4005,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e878f9a05d1d45d48df3b277ad53027c",
            "value": 4005
          }
        },
        "bab3459c8f2249f2b6dd652277887f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a03176a2fd654572870d8148da0b8490",
            "placeholder": "",
            "style": "IPY_MODEL_84577ebc3716498096cc11c9755645b7",
            "value": " 4005/4005 [00:05&lt;00:00, 856.47 examples/s]"
          }
        },
        "f5f34e6534474cf0a1711e3f2e5244fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaf78d8607384b448240f215bb35d6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d846bdfe07634507bd7e7763954cb574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de2fe3b4af704a5b8310fc0a5762f072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e878f9a05d1d45d48df3b277ad53027c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a03176a2fd654572870d8148da0b8490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84577ebc3716498096cc11c9755645b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7d368d29a484124b17d372840be401e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50f00afc76694e128950b90b44b81022",
              "IPY_MODEL_e45eb53bbea14368aa881072c2111354",
              "IPY_MODEL_4770778950a546479f7e68c0890f3303"
            ],
            "layout": "IPY_MODEL_84b3ed4d43a24feabb236f93f8ac026a"
          }
        },
        "50f00afc76694e128950b90b44b81022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f9b029fad5146588892dd3b9a74a41b",
            "placeholder": "",
            "style": "IPY_MODEL_87cb15e702474ecb8722ce59ce960afa",
            "value": "Map: 100%"
          }
        },
        "e45eb53bbea14368aa881072c2111354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc0e80889fc44aac8c3364f55d9912a8",
            "max": 3160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32d5a4754bcb4f6d98529f68648445ae",
            "value": 3160
          }
        },
        "4770778950a546479f7e68c0890f3303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf6f493d3ae94ab28e12c2587bf30f4e",
            "placeholder": "",
            "style": "IPY_MODEL_939ba9c303ef407d9462b1b4e7cc7fcc",
            "value": " 3160/3160 [00:03&lt;00:00, 937.47 examples/s]"
          }
        },
        "84b3ed4d43a24feabb236f93f8ac026a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9b029fad5146588892dd3b9a74a41b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87cb15e702474ecb8722ce59ce960afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc0e80889fc44aac8c3364f55d9912a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d5a4754bcb4f6d98529f68648445ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf6f493d3ae94ab28e12c2587bf30f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "939ba9c303ef407d9462b1b4e7cc7fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1769a159f17b4c82990e257aab98d0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b568c56ea32446b92eb421fcced953e",
              "IPY_MODEL_eba689cc3a9b451383eaab85cbb18f62",
              "IPY_MODEL_a51d37c7dc3e4cd7b152f80f479f609b"
            ],
            "layout": "IPY_MODEL_881912b21c4c47d6a8f4a6e1c8cb903b"
          }
        },
        "2b568c56ea32446b92eb421fcced953e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0bfae6dafcf4e5f8df2cd062868c3bb",
            "placeholder": "",
            "style": "IPY_MODEL_2249e3c697454b9baa7e230a75c1e762",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "eba689cc3a9b451383eaab85cbb18f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e25064ad6a9c48d0b0e3964fab69a875",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f452275552674a9c93eec80cb561ed9f",
            "value": 3
          }
        },
        "a51d37c7dc3e4cd7b152f80f479f609b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_226de1624f784403ac202bff645fda01",
            "placeholder": "",
            "style": "IPY_MODEL_8fd1b3a43d3e4273aeea3cd57aee7632",
            "value": " 3/3 [05:27&lt;00:00, 101.39s/it]"
          }
        },
        "881912b21c4c47d6a8f4a6e1c8cb903b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0bfae6dafcf4e5f8df2cd062868c3bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2249e3c697454b9baa7e230a75c1e762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e25064ad6a9c48d0b0e3964fab69a875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f452275552674a9c93eec80cb561ed9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "226de1624f784403ac202bff645fda01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fd1b3a43d3e4273aeea3cd57aee7632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79878dfd4f074ef2ab74cbea6f29537e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63452e82f1314f629004d7946606c051",
              "IPY_MODEL_d9ea08ec188445009a9f6d661eee01d7",
              "IPY_MODEL_253008ff076246b4b6f49cffcbbb6742"
            ],
            "layout": "IPY_MODEL_c6fc5bcd701b4bca9430e9a75f69e584"
          }
        },
        "63452e82f1314f629004d7946606c051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0eb62e403be4b4fa799c9e6968313e0",
            "placeholder": "",
            "style": "IPY_MODEL_a59469f542ed48b98a181cb4d609f371",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d9ea08ec188445009a9f6d661eee01d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b156f03e576e481fb47d14e6eecba7d8",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01bfc2ce68214c548c468f8ae75a3b97",
            "value": 3
          }
        },
        "253008ff076246b4b6f49cffcbbb6742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dca859c89af942fd862a0a9ba4b99bd0",
            "placeholder": "",
            "style": "IPY_MODEL_6282d1bae8b549be8cc100cda1414cb0",
            "value": " 3/3 [02:20&lt;00:00, 45.15s/it]"
          }
        },
        "c6fc5bcd701b4bca9430e9a75f69e584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0eb62e403be4b4fa799c9e6968313e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a59469f542ed48b98a181cb4d609f371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b156f03e576e481fb47d14e6eecba7d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01bfc2ce68214c548c468f8ae75a3b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dca859c89af942fd862a0a9ba4b99bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6282d1bae8b549be8cc100cda1414cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdaf64ecf83b4776817ecfb40f2cecca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d013fe00af34e24acea8dfa7464ae30",
              "IPY_MODEL_8fbdb690805f49f9a638e11dd35767d1",
              "IPY_MODEL_e26f9958e47f4780b56a434359cccac8"
            ],
            "layout": "IPY_MODEL_0bbd85c681dc465c8c999ab8e79d4b7a"
          }
        },
        "2d013fe00af34e24acea8dfa7464ae30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab0f074dd9b44b61928671634d0f6f88",
            "placeholder": "",
            "style": "IPY_MODEL_56cca52cec0f42159051013a1da252b3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8fbdb690805f49f9a638e11dd35767d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638b611796a644c88efc0047f21827c8",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e42ceb465fa4d9c87e149805b3bf29e",
            "value": 3
          }
        },
        "e26f9958e47f4780b56a434359cccac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c61fbe85ac994a179a12d3f3f1470b46",
            "placeholder": "",
            "style": "IPY_MODEL_58b7d2900bb444309c42481f9f8a22fd",
            "value": " 3/3 [02:28&lt;00:00, 47.56s/it]"
          }
        },
        "0bbd85c681dc465c8c999ab8e79d4b7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab0f074dd9b44b61928671634d0f6f88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56cca52cec0f42159051013a1da252b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "638b611796a644c88efc0047f21827c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e42ceb465fa4d9c87e149805b3bf29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c61fbe85ac994a179a12d3f3f1470b46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58b7d2900bb444309c42481f9f8a22fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}